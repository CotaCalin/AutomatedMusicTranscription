\newpage
\section{Related Work}

Automatic music transcription (AMT) has been attempted since the 1970s and polyphonic music transcription dates to the 1990s \cite{REF:1}
\par

\subsection{State of the art in AMT}

There has been substantial progress made in the field of AMT. Neural networks, in particular, have met and surpassed the performance of traditional pitch recognition techniques on polyphonic audio.
\par

A model used in \cite{REF:2} uses 87 Support Vector Machine (SVM) classifiers to perform frame-level classification with the advantage of simplicity, and then a Hidden Markov Model (HMM) post-processing was adopted to smooth the results. On top of it, Deep Belief Network(DBN) was added to learn higher layer representation of features in \cite{REF:3}. Since none of the approaches has reached the same level of accuracy as human experts, most music transcription work is completed by musicians. With the development of deep learning in recent years, many researchers were inspired to apply networks to accomplish AMT. A model based on Convolutional Neural Networks (CNN) was proposed in \cite{REF:4}. More models adopted Reccurent Neural Networks (RNN) or Long Short-Term Memory (LSTM) due to its capability of dealing with sequential data \cite{REF:1} \cite{REF:5} \cite{REF:6}. In \cite{REF:7}, 5 models were compared and the ConvNet model was reported as resulting in the best performance.
\par

The first majort AMT work is Smaragdis et al.\cite{REF:8}. This approach uses Non-Negative Matrix Factorization (NMF). This is the main methodology employed in software for automatic transcription, but it has it's limitations. For example, it needs to know how many individual notes are desired for the transcription (information that is not always available).
\par

The next work worth mentioning is Emiya et al.\cite{REF:9}, not because of their transcription system (as it was out-performed in the same year), but because of the dataset they created that has become the standard in evaluating any multi-pitch estimation system. They created the MIDI-Aligned Piano Sounds (MAPS) data set composed of around 10,000 piano sounds either recorded by using an upright Disklavier piano or generated by several virtual piano software products based on sampled sounds. The dataset
consists of audio and corresponding annotations for isolated sounds, chords, and complete pieces of piano music.
\par

Sigtia et al.\cite{REF:10} built the first AMT system using CNN, outperforming the state of the art approaches using NMF. Convolutional
Neural Networks are a discriminative approach to AMT, which has been found to be a
viable alternative to spectrogram factorization techniques. Discriminative approaches
aim to directly classify features extracted from frames of audio to the output pitches.
This approach uses complex classifiers that are trained using large amounts of training
data to capture the variability in the inputs, instead of constructing an instrument
specific model. 
\par

Sigtia et al. \cite{REF:10} explored various models for pitch detection. In addition to CNNs, they tried Deep Neural Networks and Recurrent Neural Networks. The results have shown that their CNN based model outperformed the others for this task. In their paper, they propose a Music Language Model (MLM) that's based on RNNs in order to handle the polyphonic musical data. \cite{benetos}
\par

There are some products on the market, AnthemScore for example, that use CNNs for AMT. They approach note detection as an image recognition problem by creating spectrograms of the audio. They show how the spectrum or frequency content changes over time. The method used for creating the spectrograms is the constant Q transform instead of the more common Short Time Fourier Transform (STFT) method.
\par

Melodyne is a popular plugin used for Music Transcription and Pitch Correction. It costs up to \$700. 	
The Melodic and Polyphonic algorithms offer you, in the case of vocals as well as both mono- and polyphonic instruments, full access to the notes of which the sound is composed as well as to their musical parameters.
There's no public information about what approach they used.
\par

\subsection{CNN approach to AMT}


